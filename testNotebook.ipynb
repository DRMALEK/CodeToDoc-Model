{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasetUtils import load_dataset\n",
    "from TranslationModel import TranslationModel\n",
    "import rouge\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils  import preprocess_sentence\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2c8873a498d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fix tensorflow out of memory problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mphysical_devices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphysical_devices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# fix tensorflow out of memory problem\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset  ...\n",
      "Loading the model ...\n",
      "start training ...\n",
      "Initializing from scratch.\n",
      "Current Epoch  0\n",
      "Epoch 1 Batch 1 Loss 3.0854\n",
      "Epoch 1 Batch 101 Loss 2.6801\n",
      "Epoch 1 Batch 201 Loss 2.1105\n",
      "Epoch 1 Batch 301 Loss 1.7670\n",
      "Epoch 1 Batch 401 Loss 1.7573\n",
      "Epoch 1 Batch 501 Loss 1.7758\n",
      "Epoch 1 Batch 601 Loss 1.6424\n",
      "Epoch 1 Batch 701 Loss 1.6066\n",
      "Epoch 1 Batch 801 Loss 2.1610\n",
      "Epoch 1 Batch 901 Loss 2.1540\n",
      "Epoch 1 Batch 1001 Loss 1.7653\n",
      "Epoch 1 Batch 1101 Loss 1.5276\n",
      "Epoch 1 Batch 1201 Loss 1.7173\n",
      "Epoch 1 Batch 1301 Loss 2.2282\n",
      "Epoch 1 Loss 1.9792\n",
      "Time taken for 1 epoch 2350.40 sec\n",
      "\n",
      "Current Epoch  1\n",
      "Epoch 2 Batch 1 Loss 1.6232\n",
      "Epoch 2 Batch 101 Loss 1.6819\n",
      "Epoch 2 Batch 201 Loss 1.2352\n",
      "Epoch 2 Batch 301 Loss 2.0376\n",
      "Epoch 2 Batch 401 Loss 1.6086\n",
      "Epoch 2 Batch 501 Loss 1.3106\n",
      "Epoch 2 Batch 601 Loss 2.0231\n",
      "Epoch 2 Batch 701 Loss 1.4395\n",
      "Epoch 2 Batch 801 Loss 1.1456\n",
      "Epoch 2 Batch 901 Loss 1.8855\n",
      "Epoch 2 Batch 1001 Loss 1.7676\n",
      "Epoch 2 Batch 1101 Loss 1.7884\n",
      "Epoch 2 Batch 1201 Loss 1.5384\n",
      "Epoch 2 Batch 1301 Loss 1.0191\n",
      "validiaton loss: 30.016023635864258  \n",
      " rouge score {'rouge-1': {'f': 0.004342818832796798, 'p': 0.5746273216031245, 'r': 0.0021796459284478364}, 'rouge-2': {'f': 0.004098302286246782, 'p': 0.5608314794215775, 'r': 0.002056665769249585}, 'rouge-l': {'f': 0.16843258698828614, 'p': 0.09407361943489984, 'r': 0.9747067448680352}}\n",
      "Epoch 2 Loss 1.5921\n",
      "Time taken for 1 epoch 3696.00 sec\n",
      "\n",
      "Current Epoch  2\n",
      "Epoch 3 Batch 1 Loss 1.2225\n",
      "Epoch 3 Batch 101 Loss 1.1452\n",
      "Epoch 3 Batch 201 Loss 1.3112\n",
      "Epoch 3 Batch 301 Loss 1.2200\n",
      "Epoch 3 Batch 401 Loss 1.4161\n",
      "Epoch 3 Batch 501 Loss 1.2463\n",
      "Epoch 3 Batch 601 Loss 1.3065\n",
      "Epoch 3 Batch 701 Loss 1.3540\n",
      "Epoch 3 Batch 801 Loss 1.3713\n",
      "Epoch 3 Batch 901 Loss 2.0832\n",
      "Epoch 3 Batch 1001 Loss 1.5422\n",
      "Epoch 3 Batch 1101 Loss 1.2762\n",
      "Epoch 3 Batch 1201 Loss 1.0245\n",
      "Epoch 3 Batch 1301 Loss 1.0246\n",
      "Epoch 3 Loss 1.3501\n",
      "Time taken for 1 epoch 1755.92 sec\n",
      "\n",
      "Current Epoch  3\n",
      "Epoch 4 Batch 1 Loss 1.0083\n",
      "Epoch 4 Batch 101 Loss 0.8006\n",
      "Epoch 4 Batch 201 Loss 1.1001\n",
      "Epoch 4 Batch 301 Loss 1.0288\n",
      "Epoch 4 Batch 401 Loss 1.3755\n",
      "Epoch 4 Batch 501 Loss 1.0156\n",
      "Epoch 4 Batch 601 Loss 1.3566\n",
      "Epoch 4 Batch 701 Loss 1.3150\n",
      "Epoch 4 Batch 801 Loss 1.0748\n",
      "Epoch 4 Batch 901 Loss 0.7319\n",
      "Epoch 4 Batch 1001 Loss 0.9829\n",
      "Epoch 4 Batch 1101 Loss 1.1777\n",
      "Epoch 4 Batch 1201 Loss 1.1354\n",
      "Epoch 4 Batch 1301 Loss 1.2381\n",
      "validiaton loss: 29.370563507080078  \n",
      " rouge score {'rouge-1': {'f': 0.004342957352351508, 'p': 0.5746456500488714, 'r': 0.0021797154509377117}, 'rouge-2': {'f': 0.004098440840706255, 'p': 0.5608504398826969, 'r': 0.0020567353005308746}, 'rouge-l': {'f': 0.16840481661611875, 'p': 0.09405314243929151, 'r': 0.9747067448680352}}\n",
      "Epoch 4 Loss 1.1564\n",
      "Time taken for 1 epoch 3043.67 sec\n",
      "\n",
      "Current Epoch  4\n",
      "Epoch 5 Batch 1 Loss 1.0456\n",
      "Epoch 5 Batch 101 Loss 1.0739\n",
      "Epoch 5 Batch 201 Loss 0.9610\n",
      "Epoch 5 Batch 301 Loss 1.3945\n",
      "Epoch 5 Batch 401 Loss 0.8771\n",
      "Epoch 5 Batch 501 Loss 0.9971\n",
      "Epoch 5 Batch 601 Loss 1.2217\n",
      "Epoch 5 Batch 701 Loss 0.8731\n",
      "Epoch 5 Batch 801 Loss 0.6532\n",
      "Epoch 5 Batch 901 Loss 0.9651\n",
      "Epoch 5 Batch 1001 Loss 0.8723\n",
      "Epoch 5 Batch 1101 Loss 0.9711\n",
      "Epoch 5 Batch 1201 Loss 0.7599\n",
      "Epoch 5 Batch 1301 Loss 1.1655\n",
      "Epoch 5 Loss 0.9922\n",
      "Time taken for 1 epoch 1768.34 sec\n",
      "\n",
      "Current Epoch  5\n",
      "Epoch 6 Batch 1 Loss 0.7110\n",
      "Epoch 6 Batch 101 Loss 0.7563\n",
      "Epoch 6 Batch 201 Loss 0.5332\n",
      "Epoch 6 Batch 301 Loss 0.9090\n",
      "Epoch 6 Batch 401 Loss 0.8340\n",
      "Epoch 6 Batch 501 Loss 0.5699\n",
      "Epoch 6 Batch 601 Loss 0.6252\n",
      "Epoch 6 Batch 701 Loss 0.9800\n",
      "Epoch 6 Batch 801 Loss 0.8614\n",
      "Epoch 6 Batch 901 Loss 0.8025\n",
      "Epoch 6 Batch 1001 Loss 0.7602\n",
      "Epoch 6 Batch 1101 Loss 0.7771\n",
      "Epoch 6 Batch 1201 Loss 0.5944\n",
      "Epoch 6 Batch 1301 Loss 1.0665\n",
      "validiaton loss: 30.252933502197266  \n",
      " rouge score {'rouge-1': {'f': 0.00434323439146093, 'p': 0.5746823069403646, 'r': 0.0021798544959174665}, 'rouge-2': {'f': 0.004098717949625219, 'p': 0.5608883608049333, 'r': 0.002056874363093455}, 'rouge-l': {'f': 0.16844276945805822, 'p': 0.09407950021963163, 'r': 0.9747067448680352}}\n",
      "Epoch 6 Loss 0.8513\n",
      "Time taken for 1 epoch 3050.58 sec\n",
      "\n",
      "Current Epoch  6\n",
      "Epoch 7 Batch 1 Loss 0.8325\n",
      "Epoch 7 Batch 101 Loss 0.4471\n",
      "Epoch 7 Batch 201 Loss 0.9167\n",
      "Epoch 7 Batch 301 Loss 0.5103\n",
      "Epoch 7 Batch 401 Loss 0.8054\n",
      "Epoch 7 Batch 501 Loss 0.8328\n",
      "Epoch 7 Batch 601 Loss 0.8471\n",
      "Epoch 7 Batch 701 Loss 0.7401\n",
      "Epoch 7 Batch 801 Loss 0.5134\n",
      "Epoch 7 Batch 901 Loss 0.9476\n",
      "Epoch 7 Batch 1001 Loss 0.5519\n",
      "Epoch 7 Batch 1101 Loss 0.5760\n",
      "Epoch 7 Batch 1201 Loss 0.8277\n",
      "Epoch 7 Batch 1301 Loss 0.3666\n",
      "Epoch 7 Loss 0.7278\n",
      "Time taken for 1 epoch 1770.12 sec\n",
      "\n",
      "Current Epoch  7\n",
      "Epoch 8 Batch 1 Loss 0.8018\n",
      "Epoch 8 Batch 101 Loss 0.6888\n",
      "Epoch 8 Batch 201 Loss 0.4382\n",
      "Epoch 8 Batch 301 Loss 0.3834\n",
      "Epoch 8 Batch 401 Loss 0.6725\n",
      "Epoch 8 Batch 501 Loss 0.3598\n",
      "Epoch 8 Batch 601 Loss 0.5493\n",
      "Epoch 8 Batch 701 Loss 0.6567\n",
      "Epoch 8 Batch 801 Loss 0.5768\n",
      "Epoch 8 Batch 901 Loss 0.6658\n",
      "Epoch 8 Batch 1001 Loss 0.4712\n",
      "Epoch 8 Batch 1101 Loss 0.5072\n",
      "Epoch 8 Batch 1201 Loss 0.8151\n",
      "Epoch 8 Batch 1301 Loss 0.4483\n",
      "validiaton loss: 30.872344970703125  \n",
      " rouge score {'rouge-1': {'f': 0.004343603776940175, 'p': 0.5747311827956949, 'r': 0.002180039889223806}, 'rouge-2': {'f': 0.0040990874281838325, 'p': 0.5609389220345817, 'r': 0.0020570597798435573}, 'rouge-l': {'f': 0.16845608313790295, 'p': 0.09408718724538807, 'r': 0.9747067448680352}}\n",
      "Epoch 8 Loss 0.6213\n",
      "Time taken for 1 epoch 3086.74 sec\n",
      "\n",
      "Current Epoch  8\n",
      "Epoch 9 Batch 1 Loss 0.3618\n",
      "Epoch 9 Batch 101 Loss 0.7399\n",
      "Epoch 9 Batch 201 Loss 0.6030\n",
      "Epoch 9 Batch 301 Loss 0.6143\n",
      "Epoch 9 Batch 401 Loss 0.4368\n",
      "Epoch 9 Batch 501 Loss 0.5337\n",
      "Epoch 9 Batch 601 Loss 0.7361\n",
      "Epoch 9 Batch 701 Loss 0.5432\n",
      "Epoch 9 Batch 801 Loss 0.5206\n",
      "Epoch 9 Batch 901 Loss 0.6350\n",
      "Epoch 9 Batch 1001 Loss 0.4967\n",
      "Epoch 9 Batch 1101 Loss 0.6104\n",
      "Epoch 9 Batch 1201 Loss 0.4764\n",
      "Epoch 9 Batch 1301 Loss 0.8634\n",
      "Epoch 9 Loss 0.5288\n",
      "Time taken for 1 epoch 1757.84 sec\n",
      "\n",
      "Current Epoch  9\n",
      "Epoch 10 Batch 1 Loss 0.2811\n",
      "Epoch 10 Batch 101 Loss 0.4515\n",
      "Epoch 10 Batch 201 Loss 0.4153\n",
      "Epoch 10 Batch 301 Loss 0.3178\n",
      "Epoch 10 Batch 401 Loss 0.3735\n",
      "Epoch 10 Batch 501 Loss 0.5175\n",
      "Epoch 10 Batch 601 Loss 0.5325\n",
      "Epoch 10 Batch 701 Loss 0.4021\n",
      "Epoch 10 Batch 801 Loss 0.3116\n",
      "Epoch 10 Batch 901 Loss 0.4524\n",
      "Epoch 10 Batch 1001 Loss 0.7792\n",
      "Epoch 10 Batch 1101 Loss 0.3569\n",
      "Epoch 10 Batch 1201 Loss 0.3210\n",
      "Epoch 10 Batch 1301 Loss 0.4118\n",
      "validiaton loss: 31.189632415771484  \n",
      " rouge score {'rouge-1': {'f': 0.004343834642864696, 'p': 0.5747617302052747, 'r': 0.002180155760040272}, 'rouge-2': {'f': 0.00409931835228294, 'p': 0.5609705228031118, 'r': 0.0020571756653123743}, 'rouge-l': {'f': 0.1684588855306698, 'p': 0.0940887542878276, 'r': 0.9747067448680352}}\n",
      "Epoch 10 Loss 0.4508\n",
      "Time taken for 1 epoch 3036.05 sec\n",
      "\n",
      "Current Epoch  10\n",
      "Epoch 11 Batch 1 Loss 0.3435\n",
      "Epoch 11 Batch 101 Loss 0.2029\n",
      "Epoch 11 Batch 201 Loss 0.1923\n",
      "Epoch 11 Batch 301 Loss 0.2481\n",
      "Epoch 11 Batch 401 Loss 0.4039\n",
      "Epoch 11 Batch 501 Loss 0.1542\n",
      "Epoch 11 Batch 601 Loss 0.2254\n",
      "Epoch 11 Batch 701 Loss 0.9561\n",
      "Epoch 11 Batch 801 Loss 0.4927\n",
      "Epoch 11 Batch 901 Loss 0.4085\n",
      "Epoch 11 Batch 1001 Loss 0.3788\n",
      "Epoch 11 Batch 1101 Loss 0.3031\n",
      "Epoch 11 Batch 1201 Loss 0.4140\n",
      "Epoch 11 Batch 1301 Loss 0.4190\n",
      "Epoch 11 Loss 0.3849\n",
      "Time taken for 1 epoch 1767.80 sec\n",
      "\n",
      "Current Epoch  11\n",
      "Epoch 12 Batch 1 Loss 0.3178\n",
      "Epoch 12 Batch 101 Loss 0.2629\n",
      "Epoch 12 Batch 201 Loss 0.4682\n",
      "Epoch 12 Batch 301 Loss 0.2370\n",
      "Epoch 12 Batch 401 Loss 0.4911\n",
      "Epoch 12 Batch 501 Loss 0.4493\n",
      "Epoch 12 Batch 601 Loss 0.4913\n",
      "Epoch 12 Batch 701 Loss 0.2126\n",
      "Epoch 12 Batch 801 Loss 0.2539\n",
      "Epoch 12 Batch 901 Loss 0.2531\n",
      "Epoch 12 Batch 1001 Loss 0.2728\n",
      "Epoch 12 Batch 1101 Loss 0.5382\n",
      "Epoch 12 Batch 1201 Loss 0.3331\n",
      "Epoch 12 Batch 1301 Loss 0.4890\n",
      "validiaton loss: 31.96326446533203  \n",
      " rouge score {'rouge-1': {'f': 0.004342865005981705, 'p': 0.5746334310850385, 'r': 0.0021796691026111322}, 'rouge-2': {'f': 0.004098302286246784, 'p': 0.5608314794215767, 'r': 0.0020566657692495916}, 'rouge-l': {'f': 0.16844106620856192, 'p': 0.09407806269447469, 'r': 0.9747067448680352}}\n",
      "Epoch 12 Loss 0.3283\n",
      "Time taken for 1 epoch 3203.78 sec\n",
      "\n",
      "Current Epoch  12\n",
      "Epoch 13 Batch 1 Loss 0.2296\n",
      "Epoch 13 Batch 101 Loss 0.3683\n",
      "Epoch 13 Batch 201 Loss 0.2125\n",
      "Epoch 13 Batch 301 Loss 0.3618\n",
      "Epoch 13 Batch 401 Loss 0.2706\n",
      "Epoch 13 Batch 501 Loss 0.2793\n",
      "Epoch 13 Batch 601 Loss 0.2691\n",
      "Epoch 13 Batch 701 Loss 0.2300\n",
      "Epoch 13 Batch 801 Loss 0.3075\n",
      "Epoch 13 Batch 901 Loss 0.3536\n",
      "Epoch 13 Batch 1001 Loss 0.3618\n",
      "Epoch 13 Batch 1101 Loss 0.2848\n",
      "Epoch 13 Batch 1201 Loss 0.4128\n",
      "Epoch 13 Batch 1301 Loss 0.2948\n",
      "Epoch 13 Loss 0.2831\n",
      "Time taken for 1 epoch 1743.01 sec\n",
      "\n",
      "Current Epoch  13\n",
      "Epoch 14 Batch 1 Loss 0.2556\n",
      "Epoch 14 Batch 101 Loss 0.1365\n",
      "Epoch 14 Batch 201 Loss 0.4114\n",
      "Epoch 14 Batch 301 Loss 0.2440\n",
      "Epoch 14 Batch 401 Loss 0.2725\n",
      "Epoch 14 Batch 501 Loss 0.1221\n",
      "Epoch 14 Batch 601 Loss 0.3059\n",
      "Epoch 14 Batch 701 Loss 0.2056\n",
      "Epoch 14 Batch 801 Loss 0.1865\n",
      "Epoch 14 Batch 901 Loss 0.2101\n",
      "Epoch 14 Batch 1001 Loss 0.1912\n",
      "Epoch 14 Batch 1101 Loss 0.2530\n",
      "Epoch 14 Batch 1201 Loss 0.1865\n",
      "Epoch 14 Batch 1301 Loss 0.3843\n",
      "validiaton loss: 32.93471908569336  \n",
      " rouge score {'rouge-1': {'f': 0.004342772659611886, 'p': 0.5746212121212059, 'r': 0.0021796227542845493}, 'rouge-2': {'f': 0.004098256101426973, 'p': 0.560825159267872, 'r': 0.0020566425921558205}, 'rouge-l': {'f': 0.16842240451850887, 'p': 0.09406737110112198, 'r': 0.9747067448680352}}\n",
      "Epoch 14 Loss 0.2430\n",
      "Time taken for 1 epoch 3050.25 sec\n",
      "\n",
      "Current Epoch  14\n",
      "Epoch 15 Batch 1 Loss 0.2754\n",
      "Epoch 15 Batch 101 Loss 0.1616\n",
      "Epoch 15 Batch 201 Loss 0.1030\n",
      "Epoch 15 Batch 301 Loss 0.1008\n",
      "Epoch 15 Batch 401 Loss 0.1320\n",
      "Epoch 15 Batch 501 Loss 0.2575\n",
      "Epoch 15 Batch 601 Loss 0.1990\n",
      "Epoch 15 Batch 701 Loss 0.2193\n",
      "Epoch 15 Batch 801 Loss 0.1142\n",
      "Epoch 15 Batch 901 Loss 0.2737\n",
      "Epoch 15 Batch 1001 Loss 0.2919\n",
      "Epoch 15 Batch 1101 Loss 0.1915\n",
      "Epoch 15 Batch 1201 Loss 0.1584\n",
      "Epoch 15 Batch 1301 Loss 0.1102\n",
      "Epoch 15 Loss 0.2097\n",
      "Time taken for 1 epoch 1761.52 sec\n",
      "\n",
      "Current Epoch  15\n",
      "Epoch 16 Batch 1 Loss 0.1579\n",
      "Epoch 16 Batch 101 Loss 0.1087\n",
      "Epoch 16 Batch 201 Loss 0.1976\n",
      "Epoch 16 Batch 301 Loss 0.1716\n",
      "Epoch 16 Batch 401 Loss 0.3068\n",
      "Epoch 16 Batch 501 Loss 0.1783\n",
      "Epoch 16 Batch 601 Loss 0.1613\n",
      "Epoch 16 Batch 701 Loss 0.1895\n",
      "Epoch 16 Batch 801 Loss 0.1442\n",
      "Epoch 16 Batch 901 Loss 0.2998\n",
      "Epoch 16 Batch 1001 Loss 0.1500\n",
      "Epoch 16 Batch 1101 Loss 0.1013\n",
      "Epoch 16 Batch 1201 Loss 0.1585\n",
      "Epoch 16 Batch 1301 Loss 0.2231\n",
      "validiaton loss: 34.21053695678711  \n",
      " rouge score {'rouge-1': {'f': 0.004342911179166606, 'p': 0.5746395405669544, 'r': 0.0021796922767744237}, 'rouge-2': {'f': 0.00409839465588643, 'p': 0.5608441197289905, 'r': 0.0020567121234371156}, 'rouge-l': {'f': 0.1684353640254958, 'p': 0.09407515341737203, 'r': 0.9747067448680352}}\n",
      "Epoch 16 Loss 0.1833\n",
      "Time taken for 1 epoch 3055.24 sec\n",
      "\n",
      "Current Epoch  16\n",
      "Epoch 17 Batch 1 Loss 0.2145\n",
      "Epoch 17 Batch 101 Loss 0.1047\n",
      "Epoch 17 Batch 201 Loss 0.2871\n",
      "Epoch 17 Batch 301 Loss 0.0695\n",
      "Epoch 17 Batch 401 Loss 0.3026\n",
      "Epoch 17 Batch 501 Loss 0.0808\n",
      "Epoch 17 Batch 601 Loss 0.0907\n",
      "Epoch 17 Batch 701 Loss 0.0823\n",
      "Epoch 17 Batch 801 Loss 0.4116\n",
      "Epoch 17 Batch 901 Loss 0.1431\n",
      "Epoch 17 Batch 1001 Loss 0.2480\n",
      "Epoch 17 Batch 1101 Loss 0.1268\n",
      "Epoch 17 Batch 1201 Loss 0.2190\n",
      "Epoch 17 Batch 1301 Loss 0.3878\n",
      "Epoch 17 Loss 0.1606\n",
      "Time taken for 1 epoch 1747.08 sec\n",
      "\n",
      "Current Epoch  17\n",
      "Epoch 18 Batch 1 Loss 0.1074\n",
      "Epoch 18 Batch 101 Loss 0.2375\n",
      "Epoch 18 Batch 201 Loss 0.1078\n",
      "Epoch 18 Batch 301 Loss 0.1354\n",
      "Epoch 18 Batch 401 Loss 0.0769\n",
      "Epoch 18 Batch 501 Loss 0.1759\n",
      "Epoch 18 Batch 601 Loss 0.1291\n",
      "Epoch 18 Batch 701 Loss 0.1591\n",
      "Epoch 18 Batch 801 Loss 0.0492\n",
      "Epoch 18 Batch 901 Loss 0.1498\n",
      "Epoch 18 Batch 1001 Loss 0.1187\n",
      "Epoch 18 Batch 1101 Loss 0.2297\n",
      "Epoch 18 Batch 1201 Loss 0.1991\n",
      "Epoch 18 Batch 1301 Loss 0.0650\n",
      "validiaton loss: 35.2530403137207  \n",
      " rouge score {'rouge-1': {'f': 0.004343049698721311, 'p': 0.5746578690127029, 'r': 0.0021797617992643033}, 'rouge-2': {'f': 0.004098533210345922, 'p': 0.5608630801901092, 'r': 0.0020567816547184033}, 'rouge-l': {'f': 0.1684386964701503, 'p': 0.0940771899113439, 'r': 0.9747067448680352}}\n",
      "Epoch 18 Loss 0.1433\n",
      "Time taken for 1 epoch 3064.84 sec\n",
      "\n",
      "Current Epoch  18\n",
      "Epoch 19 Batch 1 Loss 0.0827\n",
      "Epoch 19 Batch 101 Loss 0.1980\n",
      "Epoch 19 Batch 201 Loss 0.0996\n",
      "Epoch 19 Batch 301 Loss 0.1533\n",
      "Epoch 19 Batch 401 Loss 0.0609\n",
      "Epoch 19 Batch 501 Loss 0.0683\n",
      "Epoch 19 Batch 601 Loss 0.1290\n",
      "Epoch 19 Batch 701 Loss 0.0588\n",
      "Epoch 19 Batch 801 Loss 0.0663\n",
      "Epoch 19 Batch 901 Loss 0.1747\n",
      "Epoch 19 Batch 1001 Loss 0.2870\n",
      "Epoch 19 Batch 1101 Loss 0.2080\n",
      "Epoch 19 Batch 1201 Loss 0.2130\n",
      "Epoch 19 Batch 1301 Loss 0.2788\n",
      "Epoch 19 Loss 0.1272\n",
      "Time taken for 1 epoch 1756.17 sec\n",
      "\n",
      "Current Epoch  19\n",
      "Epoch 20 Batch 1 Loss 0.0744\n",
      "Epoch 20 Batch 101 Loss 0.1299\n",
      "Epoch 20 Batch 201 Loss 0.0897\n",
      "Epoch 20 Batch 301 Loss 0.0547\n",
      "Epoch 20 Batch 401 Loss 0.1278\n",
      "Epoch 20 Batch 501 Loss 0.1078\n",
      "Epoch 20 Batch 601 Loss 0.0683\n",
      "Epoch 20 Batch 701 Loss 0.1117\n",
      "Epoch 20 Batch 801 Loss 0.0594\n",
      "Epoch 20 Batch 901 Loss 0.0668\n",
      "Epoch 20 Batch 1001 Loss 0.0837\n",
      "Epoch 20 Batch 1101 Loss 0.1738\n",
      "Epoch 20 Batch 1201 Loss 0.2462\n",
      "Epoch 20 Batch 1301 Loss 0.0975\n",
      "validiaton loss: 36.14047622680664  \n",
      " rouge score {'rouge-1': {'f': 0.0043431420450911334, 'p': 0.5746700879765344, 'r': 0.0021798081475908854}, 'rouge-2': {'f': 0.004098625579985545, 'p': 0.5608757204975193, 'r': 0.0020568280089059226}, 'rouge-l': {'f': 0.16844434855765023, 'p': 0.09408049260205494, 'r': 0.9747067448680352}}\n",
      "Epoch 20 Loss 0.1125\n",
      "Time taken for 1 epoch 3116.19 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading the dataset  ...\")\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(\"./API+JAVADOC+CODE.json\")\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor,\n",
    "                                                                                                  target_tensor,\n",
    "                                                                                                test_size=0.2)\n",
    "\n",
    "\n",
    "#Parameters\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "batch_size = 16\n",
    "embedding_dim = 512\n",
    "units = 256\n",
    "epochs = 20\n",
    "vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "vocab_tar_size = len(targ_lang.word_index) + 1\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                            reduction='none')\n",
    "\n",
    "\n",
    "print(\"Loading the model ...\")\n",
    "model = TranslationModel(vocab_inp_size=vocab_inp_size, vocab_tar_size=vocab_tar_size,\n",
    "                         units=units,\n",
    "                         embedding_dim=embedding_dim,\n",
    "                         optimizer=optimizer,\n",
    "                         max_length_inp=max_length_inp,\n",
    "                         max_length_targ=max_length_targ,\n",
    "                         loss_object=loss_object,\n",
    "                         batch_size=batch_size\n",
    "                         )\n",
    "\n",
    "print(\"start training ...\")\n",
    "model.train(input_tensor_train=input_tensor_train, target_tensor_train=target_tensor_train,\n",
    "            target_lang=targ_lang, input_tensor_val=input_tensor_val, target_tensor_val=target_tensor_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_single(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ') if i in inp_lang.word_index.keys()]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "  result = '<start> '\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = model.encoder(inputs, hidden)\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden, attention_weights = model.decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "  return result, sentence\n",
    "\n",
    "def translate(sentence):\n",
    "  result, sentence = evaluate(sentence)\n",
    "  print('Input code \\n', sentence)    \n",
    "  print('Predicted javadoc \\n', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_tensor_val, target_tensor_val, targ_lang):\n",
    "    enc_hidden =  tf.zeros((len(input_tensor_val), units))    \n",
    "    enc_out, enc_hidden = model.encoder(input_tensor_val, enc_hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * len(input_tensor_val), 1)  # (1 * len(input_tensor_val))\n",
    "    predicted_sequnces = np.zeros((len(input_tensor_val), max_length_targ))\n",
    "    loss = 0.\n",
    "    for t in range(max_length_targ):\n",
    "        # preds (batch_size * voab size)\n",
    "        preds, dec_hidden, att_weights = model.decoder(dec_input,\n",
    "                                                      dec_hidden,\n",
    "                                                      enc_out)\n",
    "\n",
    "        loss += loss_function(model.loss_object, target_tensor_val[:, t], preds)\n",
    "\n",
    "        \n",
    "        # predicted_ids (batch_size * 1)\n",
    "        predicted_ids = tf.argmax(preds, 1).numpy()\n",
    "        predicted_sequnces[:, t] = predicted_ids        \n",
    "        dec_input = tf.expand_dims(predicted_ids, 1)\n",
    "    \n",
    "    refs = target_lang.sequences_to_texts(target_tensor_val)\n",
    "    preds = target_lang.sequences_to_texts(predicted_sequnces)\n",
    "\n",
    "    with open('./preds.txt') as refs, open('./refs') as preds:\n",
    "        refs.write([i + \\'n' for i in refs])\n",
    "        preds.write([i + \\'n' for i in preds])\n",
    "\n",
    "    \n",
    "    blue_score = metrics.calculate_bleu('./preds.txt', './refs')\n",
    "    rouge_score = metrics.calculate_rouge('./preds.txt', './refs')\n",
    "    \n",
    "    loss = loss / int(target_tensor_val.shape[1])        # take the average loss\n",
    "    \n",
    "    return loss, blue_score, rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run Identity: Dst tensor is not initialized. [Op:Identity]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b829dcd41426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted_sequnces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evaluate_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msequence_to_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_sequnces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#texts = targ_lang.sequences_to_texts(target_tensor_val)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-286e04cb8570>\u001b[0m in \u001b[0;36m_evaluate_2\u001b[0;34m(input_tensor_val, target_tensor_val, targ_lang)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0menc_hidden\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdec_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdec_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarg_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<start>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (1 * len(input_tensor_val))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/malekbaba_data/codes/code2seq_modified/venv/lib64/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/malekbaba_data/codes/API_CODE_COMMENT_NMT/ModelComponents.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/malekbaba_data/codes/code2seq_modified/venv/lib64/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/malekbaba_data/codes/code2seq_modified/venv/lib64/python3.6/site-packages/tensorflow_core/python/keras/layers/embeddings.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'int32'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'int64'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/malekbaba_data/codes/code2seq_modified/venv/lib64/python3.6/site-packages/tensorflow_core/python/ops/embedding_ops.py\u001b[0m in \u001b[0;36membedding_lookup\u001b[0;34m(params, ids, partition_strategy, name, validate_indices, max_norm)\u001b[0m\n\u001b[1;32m    321\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m       \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m       transform_fn=None)\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/malekbaba_data/codes/code2seq_modified/venv/lib64/python3.6/site-packages/tensorflow_core/python/ops/embedding_ops.py\u001b[0m in \u001b[0;36m_embedding_lookup_and_transform\u001b[0;34m(params, ids, partition_strategy, name, max_norm, transform_fn)\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0;31m# params. Similar to the case np > 1 where parallel_dynamic_stitch is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0;31m# outside the scioe of all with ops.colocate_with(params[p]).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m       \u001b[0;31m# Flatten the ids. There are two cases where we need to do this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/malekbaba_data/codes/code2seq_modified/venv/lib64/python3.6/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/malekbaba_data/codes/code2seq_modified/venv/lib64/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/malekbaba_data/codes/code2seq_modified/venv/lib64/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   3824\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3825\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3826\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3827\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[0;32m/data/malekbaba_data/codes/code2seq_modified/venv/lib64/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/malekbaba_data/codes/code2seq_modified/venv/lib64/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run Identity: Dst tensor is not initialized. [Op:Identity]"
     ]
    }
   ],
   "source": [
    "predicted_sequnces = _evaluate_2(input_tensor_val, target_tensor_val, targ_lang)\n",
    "sequence_to_texts(predicted_sequnces, input_tensor_val, targ_lang)\n",
    "#texts = targ_lang.sequences_to_texts(target_tensor_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input code: <start> view getactionitemview int position final recyclerview . viewholder holder mactionsstylist . getactionsgridview . findviewholderforposition position return holder null ? null holder . itemview <end>\n",
      "\n",
      "Predicted javadoc: <start> int getcolor return drawable <end> \n"
     ]
    }
   ],
   "source": [
    "sentence = \"View getActionItemView(int position) {\\n        final RecyclerView.ViewHolder holder = mActionsStylist.getActionsGridView()\\n                    .findViewHolderForPosition(position);\\n        return holder == null ? null : holder.itemView;\\n    }\"\n",
    "#sentence = \"void start() { checkStarted(false); mStarted = true; mHeifEncoder.start(); }                 .findViewHolderForPosition(position);\\n        return holder == null ? null : holder.itemView;\\n    }\"\n",
    "#sentence = \"void addAttribute(String name, String type, String value) { names.add(name); types.add(type); values.add(value); }\"\n",
    "#sentence = \"final int getVolumeControl() { return mControlType; }\"\n",
    "\n",
    "translate(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3f1a31df774c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'malek'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'baba'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not list"
     ]
    }
   ],
   "source": [
    "with open('test.txt', 'w+') as out:\n",
    "    out.write([i + '\\n' for i in ['malek', 'baba']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
